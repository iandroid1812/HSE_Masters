# HSE_Masters

## Table of contents
* [General info](#general-info)
* [Project structure](#project-structure)
* [Setup](#setup)
    - [Conda](#conda)
    - [Pip](#pip)
* [Notes](#notes)

## General info
This project is ...

## Project structure

* [Project_Files](Project_Files)
    - [Financial](Project_Files/Financial) has notebooks regarding stock market data 
    - [Twitter](Project_Files/Twitter) twitter dataset exploration, sentence embeddings and exploration of sentiment score feature in the separate notebook
    - [Preprocessed_Files](Project_Files/Preprocessed_Files) files made by prediction and preprocessing functions saved for a later use in pickle format not to repeat calculations aall over again every time 
        + [sentence embeddings](Project_Files/Preprocessed_Files/embeddings)
        + [historical predictions](Project_Files/Preprocessed_Files/historical) of validation datasets
        + [preprocessed files](Project_Files/Preprocessed_Files/preprocessing)
        + [sentiment score](Project_Files/Preprocessed_Files/sentiment) from multiple models
        + [BERTopic models](Project_Files/Preprocessed_Files/topics) for each company
        + [total dataframes](Project_Files/Preprocessed_Files/total/total_df.pkl) combining all the data required for training
        + [twitter files](Project_Files/Preprocessed_Files/tweets) for all companies
        + etc.
    - [TimeSeries_Prediction](Project_Files/TimeSeries_Prediction)
        + [darts_logs](Project_Files/TimeSeries_Prediction/darts_logs) stores checkpoint files for trained models
        + jupyter notebooks used for model training
    - [helper_funcs](Project_Files/helper_funcs) contains multiple helper functions used throught the project to collect the data, make predictions as well as preprocessing, etc.
    - [models](Project_Files/models) stores the init files of TFT, N-Linear and other models used for prediction
    - [scinet](Project_Files/scinet) an implementation of [SCINet paper](https://arxiv.org/abs/2106.09305) used for prediction of timeseries without using the covariates
    - [Others](Project_Files/Others) residual files
* [png](png) stores pictures generated by predictions and other visualization
* [Datasets](Datasets)
    - [kaggle](Datasets/kaggle) twitter dataset downloaded from [kaggle](https://www.kaggle.com/datasets/omermetinn/tweets-about-the-top-companies-from-2015-to-2020)
    - [market](Datasets/market) market data downloaded manually from [yahoo finance](https://finance.yahoo.com/)
* [emission.csv](emission.csv) file generated by [Eco2AI library](https://github.com/sb-ai-lab/Eco2AI) containing information about CO2 emissions generated during training process
    

## Setup

To run this project, install it locally using either conda or pip.

### Conda

The `environment.yml` file is stored in the root folder of this repository and lists all Python libraries on which the notebooks depend, you can replicate the environment using the following `conda` commands. 

1. First you need to create the environment:

```
conda env create -f environment.yml
```

2. Then, activate it:
```
conda activate hse-stock
```

3. Verify that the new environment was installed correctly:
```
conda env list
```

### Pip

The following command will install the packages according to the configuration file `requirements.txt` that is stored in the root folder of this repository:

```
pip install -r requirements.txt
```

## Notes

Sone of the files could not be uploaded to the Github repository due to the storage limitations, that is why all the notebooks stored in the project repository is completed with info and should not be rerun to see the results. All of the missing files will be generated automatically if you ran the functions but it will require quite some time to run.