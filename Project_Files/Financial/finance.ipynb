{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import math\n",
    "import matplotlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import yfinance as yf\n",
    "import ta\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "from pytorch_lightning.callbacks import Callback, EarlyStopping, RichProgressBar, LearningRateMonitor\n",
    "\n",
    "pl.seed_everything(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset dowmload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    id_to_ticker_path = \"Datasets/kaggle/Company_Tweet.csv\"\n",
    "    ticker_to_name_path = \"Datasets/kaggle/Company.csv\"\n",
    "\n",
    "    tickers_df = pd.read_csv(id_to_ticker_path)\n",
    "    company_name_df = pd.read_csv(ticker_to_name_path)\n",
    "    tickers = company_name_df.ticker_symbol.tolist()\n",
    "\n",
    "    market_data = yf.download((' ').join(tickers), start=\"2015-01-01\", end=\"2020-01-03\", group_by = 'ticker')\n",
    "\n",
    "    returns = pd.DataFrame()\n",
    "    \n",
    "    # for ticker in market_data.columns.levels[0]:\n",
    "    #     returns[ticker] = market_data[ticker].Close.pct_change(1).dropna()\n",
    "\n",
    "    for ticker in market_data.columns.levels[0]:\n",
    "        returns[ticker] = market_data[ticker].Close.shift(-1).dropna()\n",
    "\n",
    "    market_data = market_data.stack(level=0).rename_axis(['Date', 'Ticker']).reset_index(level=1)\n",
    "\n",
    "    market_data['Returns'] = None\n",
    "    market_data['Returns'][:-6] = returns.values.flatten()\n",
    "    # market_data = market_data.fillna(market_data.Returns.mean())\n",
    "    market_data = market_data.dropna()\n",
    "    market_data = market_data.reset_index()\n",
    "\n",
    "    market_data.to_csv('Datasets/market/market.csv', index=False)\n",
    "\n",
    "    return market_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config dictionary with changed access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttributeDict(dict):\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "config = {\n",
    "    \"batch_size\" : 64,\n",
    "    \"data_dir\" : \"Datasets/market/market.csv\",\n",
    "    \"num_workers\" : 0,\n",
    "    \"scaler\" : StandardScaler(),\n",
    "    \"ticker\" : 'AAPL',\n",
    "    \"features\" : ['Adj Close', 'Open', 'High', 'Low', 'Volume'],\n",
    "    \"target\" : ['Returns'],\n",
    "    \"test_size\" : 0.3,\n",
    "    \"val_size\" : 0.8,\n",
    "    \"n_features\" : 5,\n",
    "    \"n_hidden\" : 128,\n",
    "    \"sequence_length\" : 5,\n",
    "    \"n_layers\" : 2,\n",
    "    \"dropout\" : 0.2,\n",
    "    \"loss_function\" : nn.MSELoss(),\n",
    "    \"learning_rate\" : 1e-3,\n",
    "    \"scheduler\" : torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    \"frequency\" : 5,\n",
    "    \"monitor\" : 'val_loss',\n",
    "    \"epochs\" : 20,\n",
    "    \"optimizer\" : torch.optim.Adam,\n",
    "    \"version\": 0,\n",
    "    \"patience\": 30\n",
    "    }\n",
    "\n",
    "config = AttributeDict(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Lightning dataset + DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y, sequence_length):\n",
    "        self.X = torch.tensor(X).float()\n",
    "        self.y = torch.tensor(y).float()\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.__len__() - (self.sequence_length - 1)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.X[idx:idx + self.sequence_length], self.y[idx + self.sequence_length - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockReturnsDataModule(pl.LightningDataModule):\n",
    "  def __init__(self, config):\n",
    "    super().__init__()\n",
    "    self.config = config\n",
    "    self.batch_size = self.config.batch_size\n",
    "    self.data_dir = self.config.data_dir\n",
    "    self.num_workers = self.config.num_workers\n",
    "    self.scaler = self.config.scaler\n",
    "    self.ticker = self.config.ticker\n",
    "    self.features = self.config.features\n",
    "    self.target = self.config.target\n",
    "    self.test_size = self.config.test_size\n",
    "    self.val_size = self.config.val_size\n",
    "\n",
    "\n",
    "  def prepare_data(self):\n",
    "    dataset = pd.read_csv(self.data_dir)\n",
    "    \n",
    "    try:\n",
    "      self.dataset = dataset[dataset.Ticker == self.ticker]\n",
    "    except Exception:\n",
    "      dataset = load_data()\n",
    "    self.dataset = dataset[dataset.Ticker == self.ticker]\n",
    "\n",
    "  def setup(self, stage=None):\n",
    "\n",
    "    self.dataset = ta.add_all_ta_features(\n",
    "      self.dataset, \"Open\", \"High\", \"Low\", \"Close\",\n",
    "      \"Volume\", fillna=True\n",
    "    )\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "      self.dataset[self.features].values, self.dataset[self.target].values,\n",
    "      test_size = self.test_size, shuffle=False)\n",
    "\n",
    "    X_test, X_val, y_test, y_val = train_test_split(\n",
    "      X_test, y_test, test_size = self.val_size, shuffle=False)\n",
    "\n",
    "    self.X_train = self.scaler.fit_transform(X_train)\n",
    "    self.y_train = y_train.reshape((-1, 1))\n",
    "\n",
    "    self.X_test = self.scaler.transform(X_test)\n",
    "    self.y_test = y_test.reshape((-1, 1))\n",
    "\n",
    "    self.X_val = self.scaler.transform(X_val)\n",
    "    self.y_val = y_val.reshape((-1, 1))\n",
    "  \n",
    "  def train_dataloader(self):\n",
    "    train_dataset = TimeSeriesDataset(\n",
    "      self.X_train, self.y_train, self.config.sequence_length)\n",
    "\n",
    "    return DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size = self.batch_size,\n",
    "        shuffle = False,\n",
    "        num_workers = self.num_workers\n",
    "    )\n",
    "\n",
    "  def test_dataloader(self):\n",
    "    test_dataset = TimeSeriesDataset(\n",
    "      self.X_test, self.y_test, self.config.sequence_length)\n",
    "\n",
    "    return DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size = self.batch_size,\n",
    "        shuffle = False,\n",
    "        num_workers = self.num_workers\n",
    "    )\n",
    "\n",
    "  def val_dataloader(self):\n",
    "    val_dataset = TimeSeriesDataset(\n",
    "      self.X_val, self.y_val, self.config.sequence_length)\n",
    "\n",
    "    return DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size = self.batch_size,\n",
    "        shuffle = False,\n",
    "        num_workers = self.num_workers\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMRegressor(pl.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super(LSTMRegressor, self).__init__()\n",
    "        self.save_hyperparameters(dict(config))\n",
    "        self.config = config\n",
    "        self.n_features = self.config.n_features\n",
    "        self.n_hidden = self.config.n_hidden\n",
    "        self.sequence_length = self.config.sequence_length\n",
    "        self.batch_size = self.config.batch_size\n",
    "        self.n_layers = self.config.n_layers\n",
    "        self.dropout = self.config.dropout\n",
    "        self.loss_function = self.config.loss_function\n",
    "        self.learning_rate = self.config.learning_rate\n",
    "        self.scheduler = self.config.scheduler\n",
    "        self.optimizer = self.config.optimizer\n",
    "        self.frequency = self.config.frequency\n",
    "        self.monitor = self.config.monitor\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=self.n_features, \n",
    "                            hidden_size=self.n_hidden,\n",
    "                            num_layers=self.n_layers, \n",
    "                            dropout=self.dropout, \n",
    "                            batch_first=True)\n",
    "\n",
    "        self.linear = nn.Linear(self.n_hidden, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        y_pred = self.linear(lstm_out[:,-1])\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_function(y, y_hat)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self._shared_eval(batch, batch_idx, \"val\")\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self._shared_eval(batch, batch_idx, \"test\")\n",
    "\n",
    "    def _shared_eval(self, batch, batch_idx, prefix):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_function(y, y_hat)\n",
    "        self.log(f\"{prefix}_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optimizer(self.parameters(), lr=self.learning_rate)\n",
    "        \n",
    "        return {\n",
    "        \"optimizer\": optimizer,\n",
    "        \"lr_scheduler\": {\n",
    "            \"scheduler\": self.scheduler(optimizer, patience=20),\n",
    "            \"monitor\": \"val_loss\"\n",
    "        },\n",
    "    }\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        return self(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPrintingCallback(Callback):\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        print(\"Training has started\")\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        print(\"Training has ended\")\n",
    "\n",
    "    def on_epoch_end(self, trainer, pl_module):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(trainer, model, datamodule, type=\"val\"):\n",
    "    if type == \"test\":\n",
    "        predictions = trainer.predict(model, datamodule.test_dataloader())\n",
    "        true = [y for _, y in datamodule.test_dataloader()]\n",
    "    elif type == \"val\":\n",
    "        predictions = trainer.predict(model, datamodule.val_dataloader())\n",
    "        true = [y for _, y in datamodule.val_dataloader()]\n",
    "    elif type == \"train\":\n",
    "        predictions = trainer.predict(model, datamodule.train_dataloader())\n",
    "        true = [y for _, y in datamodule.train_dataloader()]\n",
    "\n",
    "    true = torch.cat(true).cpu().detach().numpy()\n",
    "    predictions = torch.cat(predictions).cpu().detach().numpy()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(f'Stock returns on {type} data')\n",
    "    plt.plot(true, label='true')\n",
    "    plt.plot(predictions, label='predicted')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(f'Stock returns on {type} data cumulative')\n",
    "    plt.plot(true.cumsum(), label='true')\n",
    "    plt.plot(predictions.cumsum(), label='predicted')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss(version):\n",
    "    metrics = pd.read_csv(f'./lstm/{version}/metrics.csv')\n",
    "    train_loss = metrics[['train_loss', 'step', 'epoch']][~np.isnan(metrics['train_loss'])]\n",
    "    val_loss = metrics[['val_loss', 'epoch']][~np.isnan(metrics['val_loss'])]\n",
    "    test_loss = metrics['test_loss'].iloc[-1]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 5), dpi=100)\n",
    "    axes[0].set_title('Train loss per epoch')\n",
    "    axes[0].plot(train_loss['epoch'], train_loss['train_loss'])\n",
    "    axes[1].set_title('Validation loss per epoch')\n",
    "    axes[1].plot(val_loss['epoch'], val_loss['val_loss'], color='orange')\n",
    "    plt.show(block = True)\n",
    "\n",
    "    print('MSE:')\n",
    "    print(f\"Train loss: {train_loss['train_loss'].iloc[-1]:.6f}\")\n",
    "    print(f\"Val loss:   {val_loss['val_loss'].iloc[-1]:.6f}\")\n",
    "    print(f'Test loss:  {test_loss:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_pl_trainer(config):\n",
    "    csv_logger = pl.loggers.csv_logs.CSVLogger('./', name='lstm', version=str(config.version)),\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(save_last=True)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs = config.epochs,\n",
    "        logger = csv_logger,\n",
    "        gpus = 1,\n",
    "        log_every_n_steps=1,\n",
    "        callbacks=[\n",
    "            MyPrintingCallback(),\n",
    "            EarlyStopping('val_loss', patience=config.patience),\n",
    "            RichProgressBar(refresh_rate=0),\n",
    "            checkpoint_callback,\n",
    "            LearningRateMonitor(logging_interval='epoch')\n",
    "            ])\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.epochs = 100\n",
    "config.ticker = 'AAPL'\n",
    "config.version = 'AAPL'\n",
    "config.dropout = 0.2\n",
    "config.sequence_length = 24\n",
    "config.batch_size = 70\n",
    "config.learning_rate = 1e-2\n",
    "config.test_size = 0.2\n",
    "config.val_size = 0.7\n",
    "config.patience = 30\n",
    "config.n_hidden = 32\n",
    "config.features = ['Close']\n",
    "config.n_features = len(config.features)\n",
    "config.n_layers = 2\n",
    "config.scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "config.loss = nn.MSELoss(size_average=True)\n",
    "\n",
    "model = LSTMRegressor(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = StockReturnsDataModule(config)\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup()\n",
    "trainer = setup_pl_trainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, datamodule)\n",
    "trainer.test(model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(config.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction(trainer, model, datamodule, type=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction(trainer, model, datamodule, type=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction(trainer, model, datamodule, type=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02409fb671b1ed46b2b92a72e18ceb6708409a9b6d1d011f25cd31b784aeb6de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
