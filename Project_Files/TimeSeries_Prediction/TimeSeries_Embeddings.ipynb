{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-32bf6336a3b71ff0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-32bf6336a3b71ff0\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8999;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir ./Project_Files/TimeSeries_Prediction/darts_logs --host localhost --port 8999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "parent = os.path.abspath('..')\n",
    "sys.path.insert(1, parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrei/miniconda3/envs/hse/lib/python3.10/site-packages/eco2ai/emission_track.py:135: UserWarning: \n",
      "If you use a VPN, you may have problems with identifying your country by IP.\n",
      "It is recommended to disable VPN or\n",
      "manually install the ISO-Alpha-2 code of your country during initialization of the Tracker() class.\n",
      "You can find the ISO-Alpha-2 code of your country here: https://www.iban.com/country-codes\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from helper_funcs.preprocessing import total_timeseries, get_covariates\n",
    "from helper_funcs.prediction import historical_predictions, total_validation\n",
    "from helper_funcs.inverse import inverse_func\n",
    "\n",
    "from darts.utils.model_selection import train_test_split\n",
    "from darts.dataprocessing.transformers import StaticCovariatesTransformer, Scaler\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, RichProgressBar\n",
    "from darts.models import NLinearModel, TFTModel, NaiveSeasonal, NHiTSModel\n",
    "\n",
    "import torch\n",
    "import eco2ai\n",
    "\n",
    "from models import nlinear, tft, nhits\n",
    "\n",
    "RANDOM = 101\n",
    "INPUT_CHUNK = 15\n",
    "OUTPUT_CHUNK = 5\n",
    "TEST_SIZE = 0.2\n",
    "RETRAIN=True\n",
    "LAST=False\n",
    "RESET=False\n",
    "EXP_MA = 15\n",
    "SAVE = True\n",
    "EPOCHS = 100\n",
    "\n",
    "checkpoint = ModelCheckpoint(monitor=\"val_loss\")\n",
    "progress_bar = RichProgressBar()\n",
    "tracker = eco2ai.Tracker(project_name=\"Stock_Market_Prediction\", experiment_description=\"training multiple models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[progress_bar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = total_timeseries(EXP_MA, market=True, sentiment=True, embeddings=True)\n",
    "timeseries = StaticCovariatesTransformer().fit_transform(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(\n",
    "    timeseries,\n",
    "    axis=1,\n",
    "    test_size=TEST_SIZE,\n",
    "    input_size=INPUT_CHUNK,\n",
    "    horizon=OUTPUT_CHUNK,\n",
    "    vertical_split_type='model-aware'\n",
    ")\n",
    "\n",
    "data = [train, val]\n",
    "\n",
    "target_train, past_train, future_train, target_val, past_val, future_val, target_test, past_test, future_test = get_covariates(\n",
    "    data,\n",
    "    target='Close',\n",
    "    past_covariates=[\n",
    "        # 'Adj Close',\n",
    "        'High',\n",
    "        'Low',\n",
    "        'Open',\n",
    "        'Volume',\n",
    "        # 'Volatility',\n",
    "        # 'Negative',\n",
    "        # 'Positive',\n",
    "        'sentiment_score_1',\n",
    "        # 'sentiment_score_2'\n",
    "        ],\n",
    "    embeddings=False\n",
    "    )\n",
    "\n",
    "name = 'model_tft_HHLOVS1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['High', 'Low', 'Open', 'Volume', 'sentiment_score_1'], dtype='object', name='component')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_train[0].components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_target = Scaler()\n",
    "scaler_covariates = Scaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train_scaled = scaler_target.fit_transform(target_train)\n",
    "target_val_scaled = scaler_target.transform(target_val)\n",
    "target_test_scaled = scaler_target.transform(target_test)\n",
    "\n",
    "\n",
    "past_train_scaled = scaler_covariates.fit_transform(past_train)\n",
    "past_val_scaled = scaler_covariates.transform(past_val)\n",
    "past_test_scaled = scaler_covariates.transform(past_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline = NaiveSeasonal(K=5)\n",
    "\n",
    "# baseline_hist = historical_predictions(\n",
    "#     baseline, target_val_scaled, INPUT_CHUNK, OUTPUT_CHUNK, RETRAIN, LAST, \\\n",
    "#         save=SAVE, past=past_val_scaled, future=future_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.start()\n",
    "\n",
    "if name.split('_')[1] == 'nlinear':\n",
    "    model = nlinear.nlinear_emb(name, INPUT_CHUNK, OUTPUT_CHUNK, RANDOM, \\\n",
    "        callbacks, target_train_scaled, target_val_scaled, past_train_scaled, past_val_scaled, \\\n",
    "            future_train, future_val, EPOCHS)\n",
    "            \n",
    "    model = NLinearModel.load_from_checkpoint(name, best=True, map_location=torch.device(\"cuda:0\"))\n",
    "\n",
    "if name.split('_')[1] == 'tft':\n",
    "    model = tft.tft_set(name, INPUT_CHUNK, OUTPUT_CHUNK, RANDOM, \\\n",
    "        callbacks, target_train_scaled, target_val_scaled, past_train_scaled, past_val_scaled, \\\n",
    "            future_train, future_val, EPOCHS)\n",
    "    \n",
    "    model = TFTModel.load_from_checkpoint(name, best=True, map_location=torch.device(\"cuda:0\"))\n",
    "\n",
    "if name.split('_')[1] == 'nhits':\n",
    "    model = nhits.nhits(name, INPUT_CHUNK, OUTPUT_CHUNK, RANDOM, \\\n",
    "        callbacks, target_train_scaled, target_val_scaled, past_train_scaled, past_val_scaled, \\\n",
    "            future_train, future_val, EPOCHS)\n",
    "            \n",
    "    model = NHiTSModel.load_from_checkpoint(name, best=True, map_location=torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = historical_predictions(\n",
    "    model, target_val_scaled, INPUT_CHUNK, OUTPUT_CHUNK, RETRAIN, LAST, \\\n",
    "        save=SAVE, past=past_val_scaled, future=future_val)\n",
    "\n",
    "tracker.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02409fb671b1ed46b2b92a72e18ceb6708409a9b6d1d011f25cd31b784aeb6de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
