{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir ./darts_logs --host localhost --port 8099"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "parent = os.path.abspath('..')\n",
    "sys.path.insert(1, parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrei/Documents/HSE_Masters/HSE_Masters/tft_env/lib/python3.10/site-packages/eco2ai/emission_track.py:135: UserWarning: \n",
      "If you use a VPN, you may have problems with identifying your country by IP.\n",
      "It is recommended to disable VPN or\n",
      "manually install the ISO-Alpha-2 code of your country during initialization of the Tracker() class.\n",
      "You can find the ISO-Alpha-2 code of your country here: https://www.iban.com/country-codes\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from helper_funcs.preprocessing import total_timeseries, get_covariates\n",
    "from helper_funcs.prediction import historical_predictions, total_validation\n",
    "from helper_funcs.inverse import inverse_func\n",
    "\n",
    "from darts.utils.model_selection import train_test_split\n",
    "from darts.dataprocessing.transformers import StaticCovariatesTransformer, Scaler\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, RichProgressBar\n",
    "from darts.models import NLinearModel, TFTModel, NaiveSeasonal, NHiTSModel\n",
    "\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "import eco2ai\n",
    "\n",
    "from models import nlinear, tft, nhits\n",
    "\n",
    "RANDOM = 101\n",
    "INPUT_CHUNK = 15\n",
    "OUTPUT_CHUNK = 3\n",
    "TEST_SIZE = 0.2\n",
    "RETRAIN=True\n",
    "LAST=False\n",
    "RESET=False\n",
    "EXP_MA = 15\n",
    "SAVE = True\n",
    "EPOCHS = 100\n",
    "\n",
    "checkpoint = ModelCheckpoint(monitor=\"val_loss\")\n",
    "progress_bar = RichProgressBar()\n",
    "tracker = eco2ai.Tracker(project_name=\"Stock_Market_Prediction\", experiment_description=\"training multiple models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[progress_bar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = total_timeseries(EXP_MA, market=True, sentiment=True, embeddings=True, large=True)\n",
    "timeseries = StaticCovariatesTransformer().fit_transform(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(6):\n",
    "#     timeseries[i].to_pickle(f'./ts_pickle/timeseries_{i}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(\n",
    "    timeseries,\n",
    "    axis=1,\n",
    "    test_size=TEST_SIZE,\n",
    "    input_size=INPUT_CHUNK,\n",
    "    horizon=OUTPUT_CHUNK,\n",
    "    vertical_split_type='model-aware'\n",
    ")\n",
    "\n",
    "data = [train, val]\n",
    "\n",
    "target_train, past_train, future_train, target_val, past_val, future_val, target_test, past_test, future_test = get_covariates(\n",
    "    data,\n",
    "    target='Close',\n",
    "    past_covariates=[\n",
    "        # 'Adj Close',\n",
    "        'High',\n",
    "        'Low',\n",
    "        'Open',\n",
    "        'Volume',\n",
    "        # 'Volatility',\n",
    "        # 'Negative',\n",
    "        # 'Positive',\n",
    "        # 'sentiment_score_1',\n",
    "        # 'sentiment_score_2'\n",
    "        ],\n",
    "    embeddings=True\n",
    "    )\n",
    "\n",
    "name = 'model_TFT_HLOVE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['High', 'Low', 'Open', 'Volume', '0', '1', '2', '3', '4', '5',\n",
       "       ...\n",
       "       '758', '759', '760', '761', '762', '763', '764', '765', '766', '767'],\n",
       "      dtype='object', name='component', length=772)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_train[0].components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_target = Scaler()\n",
    "scaler_covariates = Scaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train_scaled = scaler_target.fit_transform(target_train)\n",
    "target_val_scaled = scaler_target.transform(target_val)\n",
    "target_test_scaled = scaler_target.transform(target_test)\n",
    "\n",
    "\n",
    "past_train_scaled = scaler_covariates.fit_transform(past_train)\n",
    "past_val_scaled = scaler_covariates.transform(past_val)\n",
    "past_test_scaled = scaler_covariates.transform(past_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline = NaiveSeasonal(K=5)\n",
    "\n",
    "# baseline_hist = historical_predictions(\n",
    "#     baseline, target_val_scaled, INPUT_CHUNK, OUTPUT_CHUNK, RETRAIN, LAST, \\\n",
    "#         save=SAVE, past=past_val_scaled, future=future_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracker.start()\n",
    "\n",
    "# if name.split('_')[1] == 'nlinear':\n",
    "#     model = nlinear.nlinear_emb(name, INPUT_CHUNK, OUTPUT_CHUNK, RANDOM, \\\n",
    "#         callbacks, target_train_scaled, target_val_scaled, past_train_scaled, past_val_scaled, \\\n",
    "#             future_train, future_val, EPOCHS)\n",
    "            \n",
    "#     model = NLinearModel.load_from_checkpoint(name, best=True, map_location=torch.device(\"cuda:0\"))\n",
    "\n",
    "# if name.split('_')[1] == 'tft':\n",
    "#     model = tft.tft_set(name, INPUT_CHUNK, OUTPUT_CHUNK, RANDOM, \\\n",
    "#         callbacks, target_train_scaled, target_val_scaled, past_train_scaled, past_val_scaled, \\\n",
    "#             future_train, future_val, EPOCHS)\n",
    "    \n",
    "#     model = TFTModel.load_from_checkpoint(name, best=True, map_location=torch.device(\"cuda:0\"))\n",
    "\n",
    "# if name.split('_')[1] == 'nhits':\n",
    "#     model = nhits.nhits(name, INPUT_CHUNK, OUTPUT_CHUNK, RANDOM, \\\n",
    "#         callbacks, target_train_scaled, target_val_scaled, past_train_scaled, past_val_scaled, \\\n",
    "#             future_train, future_val, EPOCHS)\n",
    "            \n",
    "#     model = NHiTSModel.load_from_checkpoint(name, best=True, map_location=torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tft.tft_set(name, INPUT_CHUNK, OUTPUT_CHUNK, RANDOM, \\\n",
    "#         callbacks, target_train_scaled, target_val_scaled, past_train_scaled, past_val_scaled, \\\n",
    "#             future_train, future_val, EPOCHS)\n",
    "    \n",
    "model = TFTModel.load_from_checkpoint(name, best=True, map_location=torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden_size', 64),\n",
       "             ('lstm_layers', 1),\n",
       "             ('num_attention_heads', 4),\n",
       "             ('full_attention', True),\n",
       "             ('feed_forward', 'SwiGLU'),\n",
       "             ('dropout', 0.25),\n",
       "             ('hidden_continuous_size', 32),\n",
       "             ('categorical_embedding_sizes', None),\n",
       "             ('add_relative_index', False),\n",
       "             ('loss_fn', DirectionalLossAll()),\n",
       "             ('likelihood', None),\n",
       "             ('norm_type', 'RMSNorm'),\n",
       "             ('input_chunk_length', 15),\n",
       "             ('output_chunk_length', 3),\n",
       "             ('torch_metrics', MeanSquaredError()),\n",
       "             ('optimizer_cls', torch.optim.adam.Adam),\n",
       "             ('optimizer_kwargs', {'lr': 3e-05}),\n",
       "             ('lr_scheduler_cls', torch.optim.lr_scheduler.StepLR),\n",
       "             ('lr_scheduler_kwargs', {'step_size': 20, 'gamma': 0.5}),\n",
       "             ('batch_size', 32),\n",
       "             ('n_epochs', 100),\n",
       "             ('model_name', 'model_TFT_HLOVE'),\n",
       "             ('log_tensorboard', True),\n",
       "             ('nr_epochs_val_period', 1),\n",
       "             ('force_reset', True),\n",
       "             ('save_checkpoints', True),\n",
       "             ('random_state', 101),\n",
       "             ('pl_trainer_kwargs',\n",
       "              {'accelerator': 'gpu',\n",
       "               'devices': -1,\n",
       "               'callbacks': [<pytorch_lightning.callbacks.progress.rich_progress.RichProgressBar at 0x7fea4e284fa0>]})])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.model_params['n_epochs'] = 100\n",
    "# model.model_params['n_epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model_params['model_name'] = name\n",
    "model.model_params['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epochs_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "trainer_params = model.trainer_params\n",
    "trainer_params.update({\n",
    "    'logger': False,\n",
    "    'enable_model_summary': False,\n",
    "    'enable_progress_bar': False\n",
    "})\n",
    "trainer_params['callbacks'] = [\n",
    "    c for c in trainer_params['callbacks'] if \n",
    "                               ('TQDMProgressBar' not in str(c.__class__))\n",
    "]\n",
    "\n",
    "model.trainer = pl.Trainer(**trainer_params)\n",
    "model.model.trainer = model.trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.model_params['force_reset'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_val =[]\n",
    "reduced_past = []\n",
    "reduced_future = []\n",
    "\n",
    "for i, j, k in zip(target_val_scaled, past_val_scaled, future_val):\n",
    "    reduced_val.append(i[:100])\n",
    "    reduced_past.append(j[:100])\n",
    "    reduced_future.append(k[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = historical_predictions(\n",
    "    model, reduced_val, INPUT_CHUNK, OUTPUT_CHUNK, RETRAIN, LAST, \\\n",
    "        save=SAVE, past=reduced_past, future=reduced_future)\n",
    "\n",
    "# tracker.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tft_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec 19 2022, 17:35:49) [GCC 12.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "586660d796fe9e55ca6dc62034e4a8d62fcc09384e0a0d2bc49bc777e729bb9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
