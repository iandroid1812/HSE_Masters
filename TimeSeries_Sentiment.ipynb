{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5fac54df8988500b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5fac54df8988500b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8099;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir ./darts_logs --host localhost --port 8099"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_funcs.data import cleaned_market\n",
    "from helper_funcs.preprocessing import timeseries_init, get_covariates\n",
    "from helper_funcs.prediction import historical_predictions, display_prediction_part\n",
    "from helper_funcs.error import error_print\n",
    "from helper_funcs.inverse import inverse_func\n",
    "\n",
    "from models import nlinear, tft, dlinear\n",
    "\n",
    "from darts import TimeSeries\n",
    "# from darts.timeseries import concatenate\n",
    "from darts.models import NaiveSeasonal\n",
    "from darts.utils.model_selection import train_test_split\n",
    "from darts.dataprocessing.transformers import StaticCovariatesTransformer, Scaler\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, RichProgressBar\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torchmetrics\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM = 101\n",
    "INPUT_CHUNK = 25\n",
    "OUTPUT_CHUNK = 5\n",
    "RETRAIN=True\n",
    "LAST=False\n",
    "RESET=False\n",
    "EXP_MA = 14\n",
    "\n",
    "checkpoint = ModelCheckpoint(monitor=\"val_loss\")\n",
    "progress_bar = RichProgressBar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[progress_bar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeseries = timeseries_init(\n",
    "#     time_col='Date',\n",
    "#     static_cols=[],\n",
    "#     value_cols=[\n",
    "#         'Adj Close',\n",
    "#         'Close',\n",
    "#         'High',\n",
    "#         'Low',\n",
    "#         'Open',\n",
    "#         'Volume'\n",
    "#     ],\n",
    "#     freq='B', # business days\n",
    "#     fill_missing=True,\n",
    "#     group_col='Ticker',\n",
    "#     type='MULTI'\n",
    "# )\n",
    "\n",
    "timeseries = timeseries_init(\n",
    "    time_col='Date',\n",
    "    static_cols=[],\n",
    "    value_cols=[\n",
    "        'Adj Close', 'Close', 'High', 'Low',\n",
    "        'Open', 'Volume', 'sentiment'],\n",
    "    freq='B', # business days\n",
    "    fill_missing=True,\n",
    "    group_col='Ticker',\n",
    "    type='Sentiment',\n",
    "    \n",
    ")\n",
    "\n",
    "timeseries = StaticCovariatesTransformer().fit_transform(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(\n",
    "    timeseries,\n",
    "    axis=1,\n",
    "    test_size=0.2,\n",
    "    input_size=INPUT_CHUNK,\n",
    "    horizon=OUTPUT_CHUNK,\n",
    "    vertical_split_type='model-aware'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040, 288)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[0]), len(val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train, past_train, future_train,target_val, past_val, future_val = get_covariates(\n",
    "        type='MULTI',\n",
    "        data={\"train\": train, \"val\": val},\n",
    "        target_col=['Close'],\n",
    "        past_cov=['High', 'Low', 'Open', 'Volume'],\n",
    "        future_cov=['holidays'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train_sent, past_train_sent, _, target_val_sent, past_val_sent, _ = get_covariates(\n",
    "        type='MULTI',\n",
    "        data={\"train\": train, \"val\": val},\n",
    "        target_col=['Close'],\n",
    "        past_cov=['High', 'Low', 'Open', 'Volume', 'sentiment'],\n",
    "        future_cov=['holidays'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_train_sent, past_train_sent, _, target_val_sent, past_val_sent, _ = get_covariates(\n",
    "#         type='MULTI',\n",
    "#         data={\"train\": train, \"val\": val},\n",
    "#         target_col=['Close'],\n",
    "#         past_cov=['sentiment'],\n",
    "#         future_cov=['holidays'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = timeseries[0]\n",
    "msft = timeseries[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>component</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>holidays</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>24.603209</td>\n",
       "      <td>27.332500</td>\n",
       "      <td>27.860001</td>\n",
       "      <td>26.837500</td>\n",
       "      <td>27.847500</td>\n",
       "      <td>212818400.0</td>\n",
       "      <td>0.451456</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>23.910091</td>\n",
       "      <td>26.562500</td>\n",
       "      <td>27.162500</td>\n",
       "      <td>26.352501</td>\n",
       "      <td>27.072500</td>\n",
       "      <td>257142000.0</td>\n",
       "      <td>0.444978</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>23.912342</td>\n",
       "      <td>26.565001</td>\n",
       "      <td>26.857500</td>\n",
       "      <td>26.157499</td>\n",
       "      <td>26.635000</td>\n",
       "      <td>263188400.0</td>\n",
       "      <td>0.416930</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>24.247650</td>\n",
       "      <td>26.937500</td>\n",
       "      <td>27.049999</td>\n",
       "      <td>26.674999</td>\n",
       "      <td>26.799999</td>\n",
       "      <td>160423600.0</td>\n",
       "      <td>0.394427</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>25.179296</td>\n",
       "      <td>27.972500</td>\n",
       "      <td>28.037500</td>\n",
       "      <td>27.174999</td>\n",
       "      <td>27.307501</td>\n",
       "      <td>237458000.0</td>\n",
       "      <td>0.367257</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25</th>\n",
       "      <td>69.623230</td>\n",
       "      <td>71.067497</td>\n",
       "      <td>71.222504</td>\n",
       "      <td>70.730003</td>\n",
       "      <td>71.172501</td>\n",
       "      <td>48478800.0</td>\n",
       "      <td>0.377232</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>71.004585</td>\n",
       "      <td>72.477501</td>\n",
       "      <td>72.495003</td>\n",
       "      <td>71.175003</td>\n",
       "      <td>71.205002</td>\n",
       "      <td>93121200.0</td>\n",
       "      <td>0.375746</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>70.977631</td>\n",
       "      <td>72.449997</td>\n",
       "      <td>73.492500</td>\n",
       "      <td>72.029999</td>\n",
       "      <td>72.779999</td>\n",
       "      <td>146266000.0</td>\n",
       "      <td>0.402397</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>71.398888</td>\n",
       "      <td>72.879997</td>\n",
       "      <td>73.172501</td>\n",
       "      <td>71.305000</td>\n",
       "      <td>72.364998</td>\n",
       "      <td>144114400.0</td>\n",
       "      <td>0.398724</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>71.920578</td>\n",
       "      <td>73.412498</td>\n",
       "      <td>73.419998</td>\n",
       "      <td>72.379997</td>\n",
       "      <td>72.482498</td>\n",
       "      <td>100805600.0</td>\n",
       "      <td>0.398128</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1303 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "component   Adj Close      Close       High        Low       Open  \\\n",
       "Date                                                                \n",
       "2015-01-02  24.603209  27.332500  27.860001  26.837500  27.847500   \n",
       "2015-01-05  23.910091  26.562500  27.162500  26.352501  27.072500   \n",
       "2015-01-06  23.912342  26.565001  26.857500  26.157499  26.635000   \n",
       "2015-01-07  24.247650  26.937500  27.049999  26.674999  26.799999   \n",
       "2015-01-08  25.179296  27.972500  28.037500  27.174999  27.307501   \n",
       "...               ...        ...        ...        ...        ...   \n",
       "2019-12-25  69.623230  71.067497  71.222504  70.730003  71.172501   \n",
       "2019-12-26  71.004585  72.477501  72.495003  71.175003  71.205002   \n",
       "2019-12-27  70.977631  72.449997  73.492500  72.029999  72.779999   \n",
       "2019-12-30  71.398888  72.879997  73.172501  71.305000  72.364998   \n",
       "2019-12-31  71.920578  73.412498  73.419998  72.379997  72.482498   \n",
       "\n",
       "component        Volume  sentiment  holidays  \n",
       "Date                                          \n",
       "2015-01-02  212818400.0   0.451456       0.0  \n",
       "2015-01-05  257142000.0   0.444978       0.0  \n",
       "2015-01-06  263188400.0   0.416930       0.0  \n",
       "2015-01-07  160423600.0   0.394427       0.0  \n",
       "2015-01-08  237458000.0   0.367257       0.0  \n",
       "...                 ...        ...       ...  \n",
       "2019-12-25   48478800.0   0.377232       1.0  \n",
       "2019-12-26   93121200.0   0.375746       0.0  \n",
       "2019-12-27  146266000.0   0.402397       0.0  \n",
       "2019-12-30  144114400.0   0.398724       0.0  \n",
       "2019-12-31  100805600.0   0.398128       0.0  \n",
       "\n",
       "[1303 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple.pd_dataframe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_target = Scaler(StandardScaler())\n",
    "scaler_past = Scaler(StandardScaler())\n",
    "\n",
    "scaler_target_sent = Scaler(StandardScaler())\n",
    "scaler_past_sent = Scaler(StandardScaler())\n",
    "\n",
    "# without sentiment\n",
    "target_train_scaled = scaler_target.fit_transform(target_train)\n",
    "target_val_scaled = scaler_target.transform(target_val)\n",
    "\n",
    "past_train_scaled = scaler_past.fit_transform(past_train)\n",
    "past_val_scaled = scaler_past.transform(past_val)\n",
    "\n",
    "# with sentiment\n",
    "target_train_sent_scaled = scaler_target_sent.fit_transform(target_train_sent)\n",
    "target_val_sent_scaled = scaler_target_sent.transform(target_val_sent)\n",
    "\n",
    "past_train_sent_scaled = scaler_past_sent.fit_transform(past_train_sent)\n",
    "past_val_sent_scaled = scaler_past_sent.transform(past_val_sent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_baseline = NaiveSeasonal(K=5)\n",
    "model_baseline.fit(target_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nlinear_default = nlinear.nlinear_default(INPUT_CHUNK, OUTPUT_CHUNK, RANDOM, \\\n",
    "    callbacks, target_train, target_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nlinear_minmax = nlinear.nlinear_minmax(INPUT_CHUNK, OUTPUT_CHUNK, RANDOM, \\\n",
    "    callbacks, target_train_scaled, target_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nlinear_minmax_cov = nlinear.nlinear_minmax_cov(INPUT_CHUNK, OUTPUT_CHUNK, RANDOM, \\\n",
    "    callbacks, target_train_scaled, target_val_scaled, past_train_scaled, past_val_scaled, \\\n",
    "        future_train, future_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nlinear_minmax_sentiment = nlinear.nlinear_minmax_sentiment(INPUT_CHUNK, OUTPUT_CHUNK, RANDOM, \\\n",
    "    callbacks, target_train_sent_scaled, target_val_sent_scaled, past_train_sent_scaled, past_val_sent_scaled, \\\n",
    "        future_train, future_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nlinear_minmax_sentiment_opt = nlinear.nlinear_minmax_sentiment_opt(INPUT_CHUNK, OUTPUT_CHUNK, RANDOM, \\\n",
    "    callbacks, target_train_sent_scaled, target_val_sent_scaled, past_train_sent_scaled, past_val_sent_scaled, \\\n",
    "        future_train, future_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tft_sentiment_opt = tft.tft_sentiment_opt(INPUT_CHUNK, OUTPUT_CHUNK, RANDOM, \\\n",
    "    callbacks, target_train_sent_scaled, target_val_sent_scaled, past_train_sent_scaled, past_val_sent_scaled, \\\n",
    "        future_train, future_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tft_custom_loss = tft.tft_custom_loss(INPUT_CHUNK, OUTPUT_CHUNK, RANDOM, \\\n",
    "    callbacks, target_train_sent_scaled, target_val_sent_scaled, past_train_sent_scaled, past_val_sent_scaled, \\\n",
    "        future_train, future_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dlinear_sentiment = dlinear.dlinear_sentiment(INPUT_CHUNK, OUTPUT_CHUNK, RANDOM, \\\n",
    "    callbacks, target_train_sent_scaled, target_val_sent_scaled, past_train_sent_scaled, past_val_sent_scaled, \\\n",
    "        future_train, future_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nlinear_myloss = nlinear.nlinear_myloss(INPUT_CHUNK, OUTPUT_CHUNK, RANDOM, \\\n",
    "    callbacks, target_train_sent_scaled, target_val_sent_scaled, past_train_sent_scaled, past_val_sent_scaled, \\\n",
    "        future_train, future_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nlinear_minmax_sentiment_opt_updated = nlinear.nlinear_minmax_sentiment_opt_updated(INPUT_CHUNK, OUTPUT_CHUNK, RANDOM, \\\n",
    "    callbacks, target_train_sent_scaled, target_val_sent_scaled, past_train_sent_scaled, past_val_sent_scaled, \\\n",
    "        future_train, future_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_baseline = historical_predictions(\n",
    "    model_baseline, target_val, INPUT_CHUNK, OUTPUT_CHUNK, RETRAIN, LAST\n",
    ")\n",
    "\n",
    "hist_def = historical_predictions(\n",
    "    model_nlinear_default, target_val, INPUT_CHUNK, OUTPUT_CHUNK, RETRAIN, LAST)\n",
    "\n",
    "hist_mm = historical_predictions(\n",
    "    model_nlinear_minmax, target_val_scaled, INPUT_CHUNK, OUTPUT_CHUNK, RETRAIN, LAST)\n",
    "\n",
    "hist_mm_cov = historical_predictions(\n",
    "    model_nlinear_minmax_cov, target_val_scaled, INPUT_CHUNK, OUTPUT_CHUNK, RETRAIN, LAST, \\\n",
    "        covariates=True, past=past_val_scaled, future=future_val\n",
    "    )\n",
    "\n",
    "hist_sentiment = historical_predictions(\n",
    "    model_nlinear_minmax_sentiment, target_val_sent_scaled, INPUT_CHUNK, OUTPUT_CHUNK, RETRAIN, LAST, \\\n",
    "        covariates=True, past=past_val_sent_scaled, future=future_val\n",
    "    )\n",
    "\n",
    "# hist_sentiment_opt = historical_predictions(\n",
    "#     model_nlinear_minmax_sentiment_opt, target_val_sent_scaled, INPUT_CHUNK, OUTPUT_CHUNK, RETRAIN, LAST, \\\n",
    "#         covariates=True, past=past_val_sent_scaled, future=future_val\n",
    "#     )\n",
    "\n",
    "# hist_tft_sentiment_opt = historical_predictions(\n",
    "#     model_tft_sentiment_opt, target_val_sent_scaled, INPUT_CHUNK, OUTPUT_CHUNK, RETRAIN, LAST, \\\n",
    "#         covariates=True, past=past_val_sent_scaled, future=future_val\n",
    "#     )\n",
    "\n",
    "# hist_dlinear_sentiment = historical_predictions(\n",
    "#     model_dlinear_sentiment, target_val_sent_scaled, INPUT_CHUNK, OUTPUT_CHUNK, RETRAIN, LAST, \\\n",
    "#         covariates=True, past=past_val_sent_scaled, future=future_val\n",
    "#     )\n",
    "\n",
    "hist_nlinear_myloss = historical_predictions(\n",
    "    model_nlinear_myloss, target_val_sent_scaled, INPUT_CHUNK, OUTPUT_CHUNK, RETRAIN, LAST, \\\n",
    "        covariates=True, past=past_val_sent_scaled, future=future_val\n",
    "    )\n",
    "\n",
    "hist_tft_custom_loss = historical_predictions(\n",
    "    model_tft_custom_loss, target_val_sent_scaled, INPUT_CHUNK, OUTPUT_CHUNK, RETRAIN, LAST, \\\n",
    "        covariates=True, past=past_val_sent_scaled, future=future_val\n",
    "    )\n",
    "\n",
    "hist_sentiment_opt_updated = historical_predictions(\n",
    "    model_nlinear_minmax_sentiment_opt_updated, target_val_sent_scaled, INPUT_CHUNK, OUTPUT_CHUNK, RETRAIN, LAST, \\\n",
    "        covariates=True, past=past_val_sent_scaled, future=future_val\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diplay_prediction(hist, target, inverse=False, scaler=None):\n",
    "    if inverse:\n",
    "        hist, target = inverse_func(scaler, hist, target)\n",
    "\n",
    "    hist.plot(label='predict')\n",
    "    target[0][30:].plot(label='true')\n",
    "\n",
    "    error_print(target[0], hist)\n",
    "\n",
    "    return hist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_baselinee = diplay_prediction(hist_baseline, target_val, inverse=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_def = diplay_prediction(hist_def, target_val, inverse=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_mm = diplay_prediction(hist_mm, target_val_scaled, inverse=True, scaler=scaler_target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_mm_cov = diplay_prediction(hist_mm_cov, target_val_scaled, inverse=True, scaler=scaler_target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_sentiment = diplay_prediction(hist_sentiment, target_val_sent_scaled, inverse=True, scaler=scaler_target_sent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_sentiment_opt = diplay_prediction(hist_sentiment_opt, target_val_sent_scaled, inverse=True, scaler=scaler_target_sent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFT opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_tft_sentiment_opt = diplay_prediction(hist_tft_sentiment_opt, target_val_sent_scaled, inverse=True, scaler=scaler_target_sent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_dlinear_sentiment = diplay_prediction(hist_dlinear_sentiment, target_val_sent_scaled, inverse=True, scaler=scaler_target_sent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_tft_custom_loss = diplay_prediction(hist_tft_custom_loss, target_val_sent_scaled, inverse=True, scaler=scaler_target_sent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment updated EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_sentiment_opt_updated = diplay_prediction(hist_sentiment_opt_updated, target_val_sent_scaled, inverse=True, scaler=scaler_target_sent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DELIMEIRET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_prediction_part(target_val, 110, 140, \\\n",
    "    {\n",
    "        'baseline': hist_baseline,\n",
    "        'default': hist_def,\n",
    "        # 'minmax': hist_mm,\n",
    "        # 'covariate': hist_mm_cov,\n",
    "        'sentiment': hist_sentiment,\n",
    "        # 'sentiment_opt': hist_sentiment_opt,\n",
    "        # 'tft': hist_tft_sentiment_opt,\n",
    "        # 'dlinear': hist_dlinear_sentiment,\n",
    "        # 'sentiment_myloss': hist_tft_custom_loss,\n",
    "        # 'sentiment EMA': hist_sentiment_opt_updated\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_prediction_part(target_val, 130, 145, \\\n",
    "    {\n",
    "        'baseline': hist_baseline,\n",
    "        'default': hist_def,\n",
    "        # 'minmax': hist_mm,\n",
    "        # 'covariate': hist_mm_cov,\n",
    "        'sentiment': hist_sentiment,\n",
    "        # 'sentiment_opt': hist_sentiment_opt,\n",
    "        # 'tft': hist_tft_sentiment_opt,\n",
    "        # 'dlinear': hist_dlinear_sentiment,\n",
    "        # 'sentiment_myloss': hist_tft_custom_loss,\n",
    "        'sentiment EMA': hist_sentiment_opt_updated\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_prediction_part(target_val, 180, 195, \\\n",
    "    {\n",
    "        'baseline': hist_baseline,\n",
    "        'default': hist_def,\n",
    "        # 'minmax': hist_mm,\n",
    "        # 'covariate': hist_mm_cov,\n",
    "        'sentiment': hist_sentiment,\n",
    "        # 'sentiment_opt': hist_sentiment_opt,\n",
    "        # 'tft': hist_tft_sentiment_opt,\n",
    "        # 'dlinear': hist_dlinear_sentiment,\n",
    "        # 'sentiment_myloss': hist_tft_custom_loss,\n",
    "        'sentiment EMA': hist_sentiment_opt_updated\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_prediction_part(target_val, 220, 240, \\\n",
    "    {\n",
    "        'baseline': hist_baseline,\n",
    "        'default': hist_def,\n",
    "        # 'minmax': hist_mm,\n",
    "        # 'covariate': hist_mm_cov,\n",
    "        'sentiment': hist_sentiment,\n",
    "        # 'sentiment_opt': hist_sentiment_opt,\n",
    "        # 'tft': hist_tft_sentiment_opt,\n",
    "        # 'dlinear': hist_dlinear_sentiment,\n",
    "        # 'sentiment_myloss': hist_tft_custom_loss,\n",
    "        'sentiment EMA': hist_sentiment_opt_updated\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_prediction_part(target_val, 260, 285, \\\n",
    "    {\n",
    "        'baseline': hist_baseline,\n",
    "        'default': hist_def,\n",
    "        # 'minmax': hist_mm,\n",
    "        # 'covariate': hist_mm_cov,\n",
    "        'sentiment': hist_sentiment,\n",
    "        # 'sentiment_opt': hist_sentiment_opt,\n",
    "        # 'tft': hist_tft_sentiment_opt,\n",
    "        # 'dlinear': hist_dlinear_sentiment,\n",
    "        # 'sentiment_myloss': hist_tft_custom_loss,\n",
    "        'sentiment EMA': hist_sentiment_opt_updated\n",
    "    })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is little difference between using MinMax scaling and the normalization that is introduced in the paper for stock prices.\n",
    "\n",
    "We will stick with minmax due to better accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "02409fb671b1ed46b2b92a72e18ceb6708409a9b6d1d011f25cd31b784aeb6de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
